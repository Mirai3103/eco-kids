import {
  navigate_to_story_tool,
  similarity_search_tool,
} from "@/lib/semilarity_search";
import { IMessage, useChatStore } from "@/stores/chat.store";
import { createDeepSeek } from "@ai-sdk/deepseek";
import { generateText, stepCountIs } from "ai";
import Constants from "expo-constants";
import React, { useCallback, useRef } from "react";

const deepseek = createDeepSeek({
  apiKey: Constants.expoConfig?.extra?.deepseekApiKey,
});

const model = deepseek("deepseek-chat");

type Status = "submitted" | "streaming" | "ready" | "error";

export function getMessageContent(message: any) {
   if (typeof message.content === "string") {
    return message.content;
   }  else if (typeof message.content === "object" && Array.isArray(message.content)) {
    return message.content.map((text: any) => text.text).join("");
   }
   console.log(message.content, "message.content");
   return "";
}

type UseAiReturn = {
  messages: IMessage[];
  status: Status;
  error: Error | undefined;
  sendMessage: (message: string) => Promise<void>;
  stop: () => void;
  setMessages: (
    messages: IMessage[] | ((messages: IMessage[]) => IMessage[])
  ) => void;
  clearMessages: () => void;
};

interface IUseAiOptions {
  onLLMGenerated?: (message: string) => void;
}

const SYSTEM_PROMPT = `Báº¡n lÃ  Greenie(má»™t nhÃ¢n váº­t trong mobile app "EcoKids") â€“ ngÆ°á»i báº¡n AI dá»… thÆ°Æ¡ng cá»§a tráº» nhá» lÃ  1 trá»£ lÃ½ A.i cá»§a app "EcoKids". 
Nhiá»‡m vá»¥ cá»§a báº¡n lÃ  trÃ² chuyá»‡n cho tráº» tá»« 3 Ä‘áº¿n 5 tuá»•i vá» chá»§ Ä‘á» báº£o vá»‡ mÃ´i trÆ°á»ng xanh vÃ  tÃ¬nh yÃªu thiÃªn nhiÃªn vÃ  nÃ³i chuyá»‡n nhÆ° 1 ngÆ°á»i báº¡n cÃ¹ng tuá»•i.

ðŸŒ± NGUYÃŠN Táº®C TRáº¢ Lá»œI:
1. LuÃ´n nÃ³i ngáº¯n gá»n, rÃµ rÃ ng, dá»… hiá»ƒu. 
   - Má»—i cÃ¢u tráº£ lá»i chá»‰ 1â€“3 cÃ¢u lÃ  Ä‘á»§.
   - DÃ¹ng cÃ¢u ngáº¯n, tá»« Ä‘Æ¡n giáº£n, vÃ­ dá»¥: "CÃ¢y giÃºp khÃ´ng khÃ­ sáº¡ch hÆ¡n."
2. Khi tráº» gÃµ sai chÃ­nh táº£, hÃ£y cá»‘ gáº¯ng hiá»ƒu Ã½ vÃ  tráº£ lá»i Ä‘Ãºng ngá»¯ cáº£nh. 
   - KhÃ´ng chÃª lá»—i sai. 
   - Náº¿u cáº§n, cÃ³ thá»ƒ nháº¹ nhÃ ng nháº¯c láº¡i tá»« Ä‘Ãºng, vÃ­ dá»¥: "Ã€, cáº­u muá»‘n nÃ³i 'cÃ¢y xanh' Ä‘Ãºng khÃ´ng?"
3. Giá»ng Ä‘iá»‡u vui váº», áº¥m Ã¡p, khuyáº¿n khÃ­ch.  
   - DÃ¹ng tá»« nhÆ° "tá»‘t láº¯m", "giá»i quÃ¡".
4. **Khi bÃ© há»i vá» má»™t cÃ¢u chuyá»‡n cá»¥ thá»ƒ hoáº·c nhÃ¢n váº­t cá»¥ thá»ƒ thÃ¬ cÃ³ thá»ƒ:
   â†’ HÃ£y **gá»i tool similarity_search_tool** Ä‘á»ƒ tÃ¬m cÃ¡c cÃ¢u chuyá»‡n tÆ°Æ¡ng tá»± trong cÆ¡ sá»Ÿ dá»¯ liá»‡u.
   - Náº¿u tÃ¬m tháº¥y, dÃ¹ng cÃ¢u chuyá»‡n Ä‘Ã³ Ä‘á»ƒ tráº£ lá»i dá»±a trÃªn cÃ¢u há»i cá»§a bÃ©, Ä‘á»«ng Ä‘á»c toÃ n bá»™ cÃ¢u chuyá»‡n.
   - Náº¿u muá»‘n Ä‘á»c toÃ n bá»™ cÃ¢u chuyá»‡n, hÃ£y gá»i tool navigate_to_story_tool Ä‘á»ƒ Ä‘iá»u hÆ°á»›ng Ä‘áº¿n trang cÃ¢u chuyá»‡n.
   - Náº¿u khÃ´ng cÃ³ káº¿t quáº£, tráº£ lá»i:
     "Tá»›i chÆ°a biáº¿t Ä‘iá»u nÃ y, mÃ¬nh cÃ¹ng tÃ¬m hiá»ƒu sau nhÃ©!"
5. Khi tráº£ lá»i cÃ¢u há»i:  
   - Giáº£i thÃ­ch báº±ng vÃ­ dá»¥ tháº­t Ä‘Æ¡n giáº£n.  
   - KhÃ´ng dÃ¹ng khÃ¡i niá»‡m phá»©c táº¡p nhÆ° "carbon dioxide" hay "Ã´ nhiá»…m vi mÃ´".
6. Náº¿u bÃ© há»i Ä‘iá»u khÃ´ng cÃ³ trong dá»¯ liá»‡u:  
   NÃ³i nháº¹ nhÃ ng: "Tá»›i chÆ°a biáº¿t Ä‘iá»u nÃ y, mÃ¬nh cÃ¹ng tÃ¬m hiá»ƒu sau nhÃ©!"
7. Tuyá»‡t Ä‘á»‘i khÃ´ng nÃ³i vá»: chÃ­nh trá»‹, tÃ´n giÃ¡o, ngÆ°á»i lá»›n, hay ná»™i dung tiÃªu cá»±c.
8. Khi bÃ© há»i vá» 1 chá»§ Ä‘á» vÃ­ dá»¥ "táº¡i sao pháº£i tiáº¿t kiá»‡m nÆ°á»›c" cá»‘ gáº¯ng dÃ¹ng tool similarity_search_tool Ä‘á»ƒ tÃ¬m cÃ¡c cÃ¢u chuyá»‡n tÆ°Æ¡ng tá»± trong cÆ¡ sá»Ÿ dá»¯ liá»‡u Ä‘á»ƒ minh há»a cho bÃ© nhÆ°ng Ä‘á»«ng spoil cÃ¢u chuyá»‡n, hÃ£y hÆ°á»›ng bÃ© Ä‘á»c cÃ¢u chuyá»‡n Ä‘Ã³.

ðŸŽ¯ Má»¥c tiÃªu:  
GiÃºp tráº» hiá»ƒu, yÃªu vÃ  báº£o vá»‡ mÃ´i trÆ°á»ng thÃ´ng qua nhá»¯ng cÃ¢u chuyá»‡n vÃ  cÃ¢u tráº£ lá»i ngáº¯n gá»n, vui váº», an toÃ n.`;
export const useAi = (options: IUseAiOptions = {}): UseAiReturn => {
  const { messages, addMessage, addMessages, setMessages, clearMessages } = useChatStore();
  const mesagesRef = useRef<IMessage[]>([]);
  const [status, setStatus] = React.useState<Status>("ready");
  const [error, setError] = React.useState<Error | undefined>(undefined);
  const controllerRef = useRef<AbortController | null>(null);
  const { onLLMGenerated } = options;
  // const { forceStop,playFastTTS,clearCache } = useTTSQueue();
  React.useEffect(() => {
    mesagesRef.current = [...messages];
  }, [messages]);

  const stop = useCallback(() => {
    controllerRef.current?.abort();
    controllerRef.current = null;
    setStatus("ready");
  }, []);

  const sendMessage = useCallback(
    async (message: string) => {
      // Validation
      if (!message.trim()) return;

      // Prevent sending while streaming
      if (status === "streaming" || status === "submitted") {
        console.warn("Already processing a message");
        return;
      }

      // Reset error state
      setError(undefined);
      setStatus("submitted");

      const userMessage: IMessage = {
        role: "user",
        content: message,
      };

      // Add user message immediately

      try {
        const controller = new AbortController();
        controllerRef.current = controller;
        setStatus("streaming");

        const currentMessages = [...mesagesRef.current, userMessage];
        console.log(
          currentMessages.length,
          "currentMessages length",

          currentMessages
        );

        const { text, response, request } = await generateText({
          model,
          messages: currentMessages as any,
          abortSignal: controller.signal,
          tools: {
            similarity_search_tool,
            navigate_to_story_tool,
          },
          system: SYSTEM_PROMPT,
          stopWhen: stepCountIs(5),
        });

        // Add assistant's response
        console.log(response.messages.length > 0, "response.messages");

        if (response.messages && response.messages.length > 0) {
          addMessages([userMessage, ...(response.messages as any)]);
        }

        // Callback with final text
        onLLMGenerated?.(text);
        setStatus("ready");
        controllerRef.current = null;
      } catch (err: any) {
        // Handle abort gracefully
        if (err.name === "AbortError") {
          console.log("Stream aborted by user");
          setStatus("ready");
          return;
        }

        // Handle other errors
        console.error("AI Generation Error:", err);
        setStatus("error");
        setError(err);
      }
    },
    [status, onLLMGenerated, addMessages]
  );

  return {
    messages,
    status,
    error,
    sendMessage,
    stop,
    setMessages,
    clearMessages,
  };
};
